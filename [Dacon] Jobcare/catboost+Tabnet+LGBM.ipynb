{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"catboost+Tabnet+LGBM.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["QdT6SwhAPVlX"],"machine_shape":"hm","mount_file_id":"1v0i4jg7QT-fyzkCKpqqcNnMYTIzPc89t","authorship_tag":"ABX9TyNfqSUsZUS1IO1o9PsTESK/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kRGzYfl4xlFX"},"outputs":[],"source":["!pip install catboost"]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"id":"L-Vc64tkwd8X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch-tabnet"],"metadata":{"id":"0xzS5B-dwex9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install xgboost"],"metadata":{"id":"bStdE5fbZlQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import platform\n","import random\n","import math\n","\n","import pandas as pd\n","import numpy as np\n","from pytorch_tabnet.tab_model import TabNetClassifier\n","from pytorch_tabnet.metrics import Metric\n","\n","import sklearn \n","from sklearn.model_selection import StratifiedKFold , KFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score \n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from lightgbm import LGBMClassifier\n","from xgboost import XGBClassifier\n","from catboost import Pool,CatBoostClassifier\n","\n","\n","import optuna\n","from optuna import Trial, visualization\n","from optuna.samplers import TPESampler\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"WA5jaf3pxsCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seed_all(seed: int = 1930):\n","\n","    print(\"Using Seed Number {}\".format(seed))\n","\n","    os.environ[\"PYTHONHASHSEED\"] = str(\n","        seed)  # set PYTHONHASHSEED env var at fixed value\n","    # torch.manual_seed(seed)\n","    # torch.cuda.manual_seed_all(seed)\n","    # torch.cuda.manual_seed(seed)  # pytorch (both CPU and CUDA)\n","    np.random.seed(seed)  # for numpy pseudo-random generator\n","    random.seed(\n","        seed)  # set fixed value for python built-in pseudo-random generator\n","    # torch.backends.cudnn.deterministic = True\n","    # torch.backends.cudnn.benchmark = False\n","    # torch.backends.cudnn.enabled = False\n","\n","\n","def seed_worker(_worker_id):\n","    # worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","    \n","seed_all(seed=1994)\n"],"metadata":{"id":"P-HArGfZx6KI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv('./drive/MyDrive/Dacon/jobcare/data/train_pp.csv')\n","df_test = pd.read_csv('./drive/MyDrive/Dacon/jobcare/data/test_pp.csv')"],"metadata":{"id":"vLimSuuYxr_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X = df_train.drop(['target'], axis=1)\n","train_y = df_train.target\n","\n","test_X = df_test"],"metadata":{"id":"sRVvlaKkxr9k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 명세서 기준 순서형 변수와 명목형 변수를 구분"],"metadata":{"id":"N9l28tqviYWb"}},{"cell_type":"code","source":["# 수치형\n","numeric_var = ['matching_num']\n","\n","# 명목형 변수\n","var = list(train_X.columns)\n","\n","cate_var = [x for x in var if x not in numeric_var]\n","cate_var"],"metadata":{"id":"rt4Y7sAApmOx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class MultiColumnLabelEncoder:\n","#     def __init__(self,columns = None):\n","#         self.columns = columns # array of column names to encode\n","\n","#     def fit(self,X,y=None):\n","#         return self # not relevant here\n","\n","#     def transform(self,X):\n","#         '''\n","#         Transforms columns of X specified in self.columns using\n","#         LabelEncoder(). If no columns specified, transforms all\n","#         columns in X.\n","#         '''\n","#         output = X.copy()\n","#         if self.columns is not None:\n","#             for col in self.columns:\n","#                 output[col] = LabelEncoder().fit_transform(output[col])\n","#         else:\n","#             for colname,col in output.iteritems():\n","#                 output[colname] = LabelEncoder().fit_transform(col)\n","#         return output\n","\n","#     def fit_transform(self,X,y=None):\n","#         return self.fit(X,y).transform(X)\n"],"metadata":{"id":"L6buJGfYxr4m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# le=MultiColumnLabelEncoder(columns=var)\n","# le.fit(train_X)\n","# train_X = le.transform(train_X)\n","# test_X = le.transform(test_X)"],"metadata":{"id":"KXjlJ8hSxr2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cardinality = train_X.apply(pd.Series.nunique)\n","cat_idxs = [ i for i, f in enumerate(var) if f in cate_var]\n","cat_dims = [cardinality[i] for i in cate_var]"],"metadata":{"id":"uqstkfebz13W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LGBM K-Fold"],"metadata":{"id":"9EdAFAJ2jSW6"}},{"cell_type":"code","source":["for c in cate_var:\n","    train_X[c] = train_X[c].astype('category')\n","    test_X[c] = test_X[c].astype('category')"],"metadata":{"id":"Oj2_HyDHliOc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* {'bagging_fraction': 0.918642726084944,\n","  'feature_fraction': 0.509220798163292,\n","  'lambda_l1': 6.755458177849535,\n","  'lambda_l2': 0.009582194283353274,\n","  'num_leaves': 24}"],"metadata":{"id":"Ev25huLmH3Mt"}},{"cell_type":"code","source":["n_splits = 30\n","LGBM_test = np.zeros(test_X.shape[0]) # test prediction\n","LGBM_train = np.zeros(train_X.shape[0])\n","\n","skf = StratifiedKFold(n_splits = n_splits, random_state = 42, shuffle = True)\n","\n","for i, (t_idx, v_idx) in enumerate(skf.split(train_X, train_y)):\n","    print(f\"============================{i+1}============================\")\n","\n","    X_train, y_train = train_X.iloc[t_idx], train_y.iloc[t_idx].values\n","    X_valid, y_valid = train_X.iloc[v_idx], train_y.iloc[v_idx].values\n","\n","    LGBM = LGBMClassifier(random_state = 42, n_estimators = 3000, \n","                          categorical_feature = cate_var, eval_metric=\"F1\",\n","                          bagging_fraction=0.918642726084944, feature_fraction=0.509220798163292,\n","                          lambda_l1=6.755458177849535, lambda_l2=0.009582194283353274,\n","                          num_leaves=24\n","                          )\n","    LGBM.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_valid, y_valid)], early_stopping_rounds = 100, verbose = 100)\n","\n","    \n","    LGBM_test += (LGBM.predict_proba(test_X)[:, 1])/n_splits # test set prediction\n","    LGBM_train[v_idx] += LGBM.predict_proba(X_valid)[:, 1]\n","\n","    # pred = LGBM.predict_proba(X_valid)[:, 1]\n","    # pred_ = np.where(pred >= 0.5 , 1, 0)\n","    # score_ = f1_score(y_valid,pred_)\n","    # LGBM_scores.append(score_)\n","    # print(f\"threshold 0.5 score: {score_}\")\n","\n","    # pred = np.where(pred >= 0.4 , 1, 0)\n","    # score = f1_score(y_valid,pred)\n","    # LGBM_scores_thres.append(score)\n","    # print(f\"threshold 0.4 score: {score}\")"],"metadata":{"id":"AECy2aYFjLxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LGBM_train"],"metadata":{"id":"yB1oWgGETzQg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold = 0.4\n","train_pred = np.where(LGBM_train >= 0.4 , 1, 0)\n","train_pred"],"metadata":{"id":"Hp-p-AmsSA96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_score = f1_score(train_pred, train_y)\n","train_score"],"metadata":{"id":"kLIK1eo2SRMU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 50fold: 0.6894\n","* 30fold: 0.6893\n","* 25fold: 0.6886\n","* 20fold: 0.6886\n","* 15fold: 0.6883\n","* 10fold: 0.6873"],"metadata":{"id":"3ODKKi8fvlXC"}},{"cell_type":"code","source":["# print(f'threshold_0.5: {np.mean(LGBM_scores)}')\n","# print(f'threshold_0.4: {np.mean(LGBM_scores_thres)}')"],"metadata":{"id":"14Z_szO5jRyz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TabNet K-Fold"],"metadata":{"id":"c_MF5uLEwrOM"}},{"cell_type":"code","source":["class F1_Score(Metric):\n","    def __init__(self):\n","        self._name = \"f1\"\n","        self._maximize = True\n","\n","    def __call__(self, y_true, y_score):\n","        score = f1_score(y_true, (y_score[:, 1]>0.5)*1)\n","        return score"],"metadata":{"id":"IA5ejWT8xPdI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_splits = 10\n","threshold = 0.4\n","Tab_test = np.zeros(test_X.shape[0]) # test prediction\n","Tab_train = np.zeros(train_X.shape[0])\n","\n","skf = StratifiedKFold(n_splits = n_splits, random_state = 42, shuffle = True)\n","\n","for i, (t_idx, v_idx) in enumerate(skf.split(train_X, train_y)):\n","    print(f\"============================{i+1}============================\")\n","\n","    X_train, y_train = train_X.iloc[t_idx].values, train_y.iloc[t_idx].values\n","    X_valid, y_valid = train_X.iloc[v_idx].values, train_y.iloc[v_idx].values\n","    Tab = TabNetClassifier(cat_idxs=cat_idxs,\n","                       cat_dims=cat_dims,\n","                       cat_emb_dim=3,\n","                       optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n","                       mask_type='entmax', # \"sparsemax\",\n","                      )\n","    Tab.fit(\n","        X_train=X_train, y_train=y_train,\n","        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","        eval_name=['train', 'val'],\n","        eval_metric=['logloss','f1'],\n","        max_epochs=100, patience=5,\n","        batch_size=1024,\n","        virtual_batch_size=256,\n","        num_workers=1,\n","        drop_last=False,\n","    )\n","\n","    Tab_test += (Tab.predict_proba(test_X.values)[:,1])/n_splits     # test set prediction\n","    Tab_train[v_idx] += Tab.predict_proba(X_valid)[:, 1]\n","    \n","    # pred = Tab.predict_proba(X_valid)[:,1]\n","    # pred_th = np.where(pred >= threshold , 1, 0)\n","    # score = f1_score(y_valid,pred_th)\n","    # Tab_scores_thres.append(score)\n","\n","    # pred_ = np.where(pred >= 0.5 , 1, 0)\n","    # score = f1_score(y_valid,pred_)\n","    # Tab_scores.append(score)"],"metadata":{"id":"DWX7f7PHP9Wy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 10fold: 0.6610, 0.6884\n","* 15fold: 0.6578, 0.6872\n","* 20fold: 0.6583, 0.6880"],"metadata":{"id":"1rMpIOYY_NWp"}},{"cell_type":"code","source":["Tab_train"],"metadata":{"id":"GThyPWjoKu5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold = 0.4\n","train_pred = np.where(Tab_train >= 0.4 , 1, 0)\n","train_pred"],"metadata":{"id":"vhZPSH9SKu5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_score = f1_score(train_pred, train_y)\n","train_score"],"metadata":{"id":"VJq-KAgiKu5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'threshold_0.5: {np.mean(Tab_scores)}')\n","print(f'threshold_0.4: {np.mean(Tab_scores_thres)}')"],"metadata":{"id":"tfSsK2BKWqB6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## stacking ensemble을 위한 column 추가"],"metadata":{"id":"Knat93gyHav5"}},{"cell_type":"code","source":["len(train_X)"],"metadata":{"id":"Y0YFchSzLNzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LGBM_train"],"metadata":{"id":"Pkxbyuv2n3JI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(Tab_train)"],"metadata":{"id":"trpsvikfn0PL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X['LGBM_prob'] = LGBM_train\n","# train_X['Tab_prob'] = Tab_train"],"metadata":{"id":"xn-cEK_ALvjV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_X['LGBM_prob'] = LGBM_test\n","# test_X['Tab_prob'] = Tab_test"],"metadata":{"id":"qQi021nqNJfy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X.to_csv('./drive/MyDrive/Dacon/jobcare/data/train_stacking.csv', index=False)\n","test_X.to_csv('./drive/MyDrive/Dacon/jobcare/data/test_stacking.csv', index=False)"],"metadata":{"id":"df4OwTXfNWAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_X = pd.read_csv('./drive/MyDrive/Dacon/jobcare/data/train_stacking.csv')\n","test_X = pd.read_csv('./drive/MyDrive/Dacon/jobcare/data/test_stacking.csv')"],"metadata":{"id":"HjWfyYF0WiFC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# catboost K-Fold"],"metadata":{"id":"MFyya1k-X_Kn"}},{"cell_type":"code","source":["# cat_features = train_X.columns[train_X.nunique() > 2].tolist()"],"metadata":{"id":"fP02K6O0aSSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["{'objective': 'CrossEntropy', 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.4079670122251873}"],"metadata":{"id":"sZAH4xn6-uhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_splits = 10\n","iterations = 3000\n","early_stopping_rounds = 300\n","CBC_test = np.zeros(test_X.shape[0])\n","CBC_train = np.zeros(train_X.shape[0])\n","threshold = 0.4\n","\n","skf = StratifiedKFold(n_splits = n_splits, random_state = 42, shuffle = True)\n","\n","for i, (t_idx, v_idx) in enumerate(skf.split(train_X, train_y)):\n","    print(f\"============================{i+1}============================\")\n","\n","    X_train, y_train = train_X.iloc[t_idx], train_y.iloc[t_idx].values\n","    X_valid, y_valid = train_X.iloc[v_idx], train_y.iloc[v_idx].values\n","    CBC = CatBoostClassifier(iterations=iterations,random_state=42,task_type=\"GPU\",\n","                             eval_metric=\"F1\",cat_features=cat_idxs,one_hot_max_size=4,\n","                             bagging_temperature=1.4079670122251873, boosting_type=\"Plain\",\n","                             bootstrap_type=\"Bayesian\", depth=12, objective=\"CrossEntropy\"\n","                             )\n","    CBC.fit(X_train, y_train, \n","            eval_set=[(X_valid, y_valid)],\n","            early_stopping_rounds=early_stopping_rounds,\n","            verbose = 100\n","        )    \n","    \n","    CBC_test += (CBC.predict_proba(test_X)[:, 1])/n_splits # test set prediction\n","    CBC_train[v_idx] = CBC.predict_proba(X_valid)[:, 1]\n","\n","    # pred = np.where(pred >= threshold , 1, 0)\n","    # score = f1_score(y_valid,pred)\n","    # CBC_scores_thres.append(score)\n","\n","    # CBC_scores.append(CBC.get_best_score()[\"validation\"][\"F1\"])"],"metadata":{"id":"K_vPiJIwqkCp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 25fold: 0.6849, 0.7119\n","* 15fold: 0.6832, 0.7121\n","* 10fold: 0.6839, 0.7123 \\***\n","* 5fold: 0.6709, 0.7096\n"],"metadata":{"id":"5uIHXNsy_4X5"}},{"cell_type":"code","source":["CBC_train"],"metadata":{"id":"TQpYrLLLA4bq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold = 0.4\n","train_pred = np.where(CBC_train >= 0.4 , 1, 0)\n","train_pred"],"metadata":{"id":"uEz-84ZTA4bq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_score = f1_score(train_pred, train_y)\n","train_score"],"metadata":{"id":"IcYEduEkA4bq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XGB K-fold"],"metadata":{"id":"QdT6SwhAPVlX"}},{"cell_type":"code","source":["n_splits = 50\n","XGB_scores = []\n","XGB_scores_thres = []\n","threshold = 0.4\n","XGB_pred = np.zeros(test_X.shape[0]) # test prediction\n","\n","skf = StratifiedKFold(n_splits = n_splits, random_state = 42, shuffle = True)\n","\n","for i, (t_idx, v_idx) in enumerate(skf.split(train_X, train_y)):\n","    print(f\"============================{i+1}============================\")\n","\n","    X_train, y_train = train_X.iloc[t_idx], train_y.iloc[t_idx].values\n","    X_valid, y_valid = train_X.iloc[v_idx], train_y.iloc[v_idx].values\n","    XGB = XGBClassifier(random_state = 42, n_estimators = 3000, eval_metric=\"F1\",\n","                        tree_method=\"gpu_hist\", enable_categorical=True, use_label_encoder=False)\n","    \n","\n","    XGB.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_valid, y_valid)], early_stopping_rounds = 100, verbose = 100)\n","\n","    \n","    XGB_pred += (XGB.predict_proba(test_X)[:, 1])/n_splits # test set prediction\n","    pred = XGB.predict_proba(X_valid)[:, 1]\n","\n","    pred_ = np.where(pred >= 0.5 , 1, 0)\n","    score_ = f1_score(y_valid,pred_)\n","    XGB_scores.append(score_)\n","    print(f\"threshold 0.5 score: {score_}\")\n","\n","    pred = np.where(pred >= 0.4 , 1, 0)\n","    score = f1_score(y_valid,pred)\n","    XGB_scores_thres.append(score)\n","    print(f\"threshold 0.4 score: {score}\")"],"metadata":{"id":"rfRXoIodPYXk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Optuna"],"metadata":{"id":"FgyciopQ1E-r"}},{"cell_type":"code","source":["train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42, stratify=train_y)"],"metadata":{"id":"4b87YuXOjLns"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* CatBoost"],"metadata":{"id":"FMly8K4v6SVc"}},{"cell_type":"code","source":["def CBC_objective(trial):\n","    param = {\n","        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n","        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n","        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n","        \"bootstrap_type\": trial.suggest_categorical(\n","            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n","        ), \"iterations\": 3000, \"random_state\": 42, \"task_type\": \"GPU\", \"eval_metric\": \"F1\", \n","        \"cat_features\": cat_idxs, \"one_hot_max_size\": 4\n","    }\n","\n","    if param[\"bootstrap_type\"] == \"Bayesian\":\n","        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n","    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n","        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n","\n","    CBC = CatBoostClassifier(**param)\n","\n","    CBC.fit(train_X, train_y, \n","            eval_set=[(valid_X, valid_y)],\n","            early_stopping_rounds=200,\n","            verbose = 100\n","    )\n","    prob = CBC.predict_proba(valid_X)[:, 1]\n","    pred = np.where(prob >= 0.4 , 1, 0)\n","    score = f1_score(pred, valid_y)\n","\n","    return score"],"metadata":{"id":"a7HybwNW2f1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CBC_study = optuna.create_study(direction=\"maximize\")\n","CBC_study.optimize(CBC_objective, n_trials=1000)"],"metadata":{"id":"utALqOsR2fzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CBC_study.best_trial.value, CBC_study.best_trial.params"],"metadata":{"id":"T49uQrZQ-ebw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(0.7083990423506532,\n"," {'objective': 'CrossEntropy', 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.4079670122251873})"],"metadata":{"id":"crjkZXHn-lw5"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","af\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Z6bkqN3N3taz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CBC_params = CBC_study.best_params\n","print(CBC_params)\n","# Optimized model\n","# CBC = CatBoostClassifier(**CBC_params)"],"metadata":{"id":"ReFJ94-v-KZE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* TabNet"],"metadata":{"id":"ttQObAk36Ys-"}},{"cell_type":"code","source":["train_X, train_y, valid_X, valid_y = train_X.values, train_y.values, valid_X.values, valid_y.values"],"metadata":{"id":"sXmhjeW1Ikt0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_splits = 10\n","threshold = 0.4\n","Tab_test = np.zeros(test_X.shape[0]) # test prediction\n","Tab_train = np.zeros(train_X.shape[0])\n","\n","skf = StratifiedKFold(n_splits = n_splits, random_state = 42, shuffle = True)\n","\n","for i, (t_idx, v_idx) in enumerate(skf.split(train_X, train_y)):\n","    print(f\"============================{i+1}============================\")\n","\n","    X_train, y_train = train_X.iloc[t_idx].values, train_y.iloc[t_idx].values\n","    X_valid, y_valid = train_X.iloc[v_idx].values, train_y.iloc[v_idx].values\n","    Tab = TabNetClassifier(cat_idxs=cat_idxs,\n","                       cat_dims=cat_dims,\n","                       cat_emb_dim=3,\n","                       optimizer_fn=torch.optim.AdamW, # Any optimizer works here\n","                       mask_type='entmax', # \"sparsemax\",\n","                      )\n","    Tab.fit(\n","        X_train=X_train, y_train=y_train,\n","        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","        eval_name=['train', 'val'],\n","        eval_metric=['logloss','f1'],\n","        max_epochs=100, patience=5,\n","        batch_size=1024,\n","        virtual_batch_size=256,\n","        num_workers=1,\n","        drop_last=False,\n","    )\n","\n","    Tab_test += (Tab.predict_proba(test_X.values)[:,1])/n_splits     # test set prediction\n","    Tab_train[v_idx] += Tab.predict_proba(X_valid)[:, 1]\n","    \n","    # pred = Tab.predict_proba(X_valid)[:,1]\n","    # pred_th = np.where(pred >= threshold , 1, 0)\n","    # score = f1_score(y_valid,pred_th)\n","    # Tab_scores_thres.append(score)\n","\n","    # pred_ = np.where(pred >= 0.5 , 1, 0)\n","    # score = f1_score(y_valid,pred_)\n","    # Tab_scores.append(score)"],"metadata":{"id":"JcYmpsuceVQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Tab_objective(trial):\n","    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n","    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n","    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n","    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n","    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n","    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n","    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n","                     lambda_sparse=lambda_sparse,\n","                     mask_type=mask_type, n_shared=n_shared,\n","                     verbose=0, cat_dims=cat_dims, cat_idxs=cat_idxs\n","                     )\n","    # param = {\n","    #     'mask_type': trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"]),\n","    #     \"n_da\": trial.suggest_int(\"n_da\", 56, 64, step=4),\n","    #     'n_steps': trial.suggest_int(\"n_steps\", 1, 3, step=1),\n","    #     \"gamma\": trial.suggest_float(\"gamma\", 1., 1.4, step=0.2),\n","    #     'n_shared': trial.suggest_int(\"n_shared\", 1, 3),\n","    #     'lambda_sparse': trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True),\n","    #     'cat_dims': cat_idxs, \"cat_dims\": cat_dims, \"cat_emb_dim\": 5, \n","    # }\n","\n","    \n","\n","    Tab = TabNetClassifier(**tabnet_params)\n","\n","    Tab.fit(\n","        X_train=train_X, y_train=train_y,\n","        eval_set=[(train_X, train_y), (valid_X, valid_y)],\n","        eval_name=['train', 'val'],\n","        eval_metric=['logloss'],\n","        max_epochs=100,\n","        batch_size=1024,\n","        virtual_batch_size=256,\n","        num_workers=1,\n","        drop_last=False,\n","    )\n","\n","    pred = Tab.predict_proba(X_valid)[:, 1]\n","    pred_ = np.where(pred >= 0.5 , 1, 0)\n","    score_ = f1_score(y_valid,pred_)\n","    print(f\"threshold 0.5 score: {score_}\")\n","\n","    return score_"],"metadata":{"id":"gdKdlvbb6apD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Tab_study = optuna.create_study(direction=\"maximize\")\n","Tab_study.optimize(Tab_objective, n_trials=2)"],"metadata":{"id":"BirbHAhi6amy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* LGBM"],"metadata":{"id":"Ok_Cj5ne9cqc"}},{"cell_type":"code","source":["for c in cate_var:\n","    train_X[c] = train_X[c].astype('category')\n","    valid_X[c] = valid_X[c].astype('category')\n","    test_X[c] = test_X[c].astype('category')"],"metadata":{"id":"IzbIFqHebu1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def LGBM_objective(trial):\n","    param = {\n","        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n","        'objective': 'regression',\n","        'learning_rate': 0.1,\n","        \"boosting\": \"gbdt\",\n","        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n","        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n","        \"bagging_freq\": 5,\n","        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n","        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n","        \"verbosity\": 100, \"random_state\": 42, \"n_estimators\":  3000, \"categorical_feature\": cate_var,\n","        \"eval_metric\": \"F1\"\n","    }\n","\n","\n","    LGBM = LGBMClassifier(**param)\n","    LGBM.fit(train_X, train_y, eval_set = [(train_X, train_y), (valid_X, valid_y)], early_stopping_rounds = 100, verbose = 100)\n","\n","    pred = LGBM.predict_proba(valid_X)[:, 1]\n","    pred_ = np.where(pred >= 0.5 , 1, 0)\n","    score_ = f1_score(valid_y,pred_)\n","    print(f\"threshold 0.5 score: {score_}\")\n","\n","\n","    return score_"],"metadata":{"id":"ZIPxW6Z2oQeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LGBM_study = optuna.create_study(direction=\"maximize\")\n","LGBM_study.optimize(LGBM_objective, n_trials=1000)"],"metadata":{"id":"o-ruWSAkjLiT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* LGBM 최적 value & parameter: (0.6480186032209709,\n"," {'bagging_fraction': 0.918642726084944,\n","  'feature_fraction': 0.509220798163292,\n","  'lambda_l1': 6.755458177849535,\n","  'lambda_l2': 0.009582194283353274,\n","  'num_leaves': 24})"],"metadata":{"id":"AdVpd3hq8Xcl"}},{"cell_type":"code","source":["LGBM_study.best_trial.value, LGBM_study.best_trial.params"],"metadata":{"id":"0Q07FRui8u-8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ensemble"],"metadata":{"id":"mkUJQyNPoRJs"}},{"cell_type":"code","source":["CBC_pred"],"metadata":{"id":"IP-tIUsBw9aE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Tab_pred"],"metadata":{"id":"nyknSgXYWvXH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LGBM_pred"],"metadata":{"id":"3M49rPiyoXUq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = [1 if value >= 0.4 else 0 for value in CBC_pred ]\n"],"metadata":{"id":"uMNGqp_P_rlx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# submission"],"metadata":{"id":"m3kKpWJX7c1a"}},{"cell_type":"code","source":["submission = pd.read_csv('./drive/MyDrive/Dacon/jobcare/data/sample_submission.csv')\n","submission['target'] = pred\n","submission.to_csv('./drive/MyDrive/Dacon/jobcare/submission/cbc+feature_add.csv',index=False)"],"metadata":{"id":"ZOp9Z5GQ_ri4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"8kXqsrz7O2Ah"},"execution_count":null,"outputs":[]}]}